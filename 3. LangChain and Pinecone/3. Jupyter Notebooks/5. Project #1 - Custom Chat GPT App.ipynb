{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "029c8a52-b02e-46fb-a2f6-04da54a15ae0",
   "metadata": {},
   "source": [
    "# Advantages of using a custon chat GPT\n",
    "\n",
    "- Increased security but enabling authentication to access company chat\n",
    "- Improved user experience by creating use cases specific to a company need\n",
    "- Greater flexifiblity by adding custom fallbacks to user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74a606c6-c87f-40b3-9a63-18ed06a8de9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af2ba68-d98f-48b9-b4db-72196ff06c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3bfcc5-8dab-4593-af23-d71e57ff6a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vagner Machado\\AppData\\Local\\Temp\\ipykernel_28828\\2034590030.py:10: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  chain = LLMChain(\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your prompt What makes the sky blue during the day and red around dusk and dawn?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'What makes the sky blue during the day and red around dusk and dawn?', 'text': \"During the day, the sky appears blue because of the way sunlight is scattered in the Earth's atmosphere. The gases and particles in the atmosphere scatter sunlight in all directions, but shorter (blue) wavelengths are scattered more than longer (red) wavelengths due to Rayleigh scattering. This causes the blue light to be scattered all around the sky, making it appear blue to our eyes.\\n\\nDuring sunrise and sunset, the sunlight has to pass through a larger portion of the Earth's atmosphere compared to when the sun is directly overhead. This means that more of the shorter blue and green wavelengths are scattered out, and the longer red and orange wavelengths are able to reach our eyes more directly. This is why the sky appears red or orange during these times, as the shorter wavelengths are scattered away and the longer wavelengths dominate the colors we see.\"}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your prompt So what can be done to change the colors?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'So what can be done to change the colors?', 'text': 'To change the colors of what specifically? Can you provide more context or details so I can assist you better?'}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your prompt bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodbye!\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=1)\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    messages=[\n",
    "        SystemMessage(content=\"You are a chatbot having a conversation with a human\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=False\n",
    ")\n",
    "while True:\n",
    "    content = input(\"Please enter your prompt\")\n",
    "    if content in [\"quit\",\"exit\", \"bye\"]:\n",
    "        print(\"goodbye!\")\n",
    "        break\n",
    "    response = chain.invoke({\"content\":content})\n",
    "    print(response)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a8a99-8c20-44a9-baea-5c6fafbf4fab",
   "metadata": {},
   "source": [
    "## As you can see there is no memory from one question to another!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40c903-7bed-48e8-8e0b-82969f07e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before workin on that , lets test the System Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb99931d-13f1-4beb-ba72-10872494203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your prompt What are the top 5 most delicious desserts in Spanish cousine?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'What are the top 5 most delicious desserts in Spanish cousine?', 'text': \"Les 5 desserts les plus délicieux de la cuisine espagnole sont la crème catalane, les churros, le flan, la tarta de Santiago et les pestiños. Avez-vous déjà goûté l'un de ces desserts espagnols?\"}\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=1)\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    messages=[\n",
    "        # SystemMessage(content=\"You are a chatbot having a conversation with a human\"),\n",
    "        SystemMessage(content=\"You are a chatbot having a conversation with a human. Respond only in French.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=False\n",
    ")\n",
    "while True:\n",
    "    content = input(\"Please enter your prompt\")\n",
    "    if content in [\"quit\",\"exit\", \"bye\"]:\n",
    "        print(\"goodbye!\")\n",
    "        break\n",
    "    response = chain.invoke({\"content\":content})\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
